[AlphaGo Zero: Starting from scratch](https://deepmind.google/discover/blog/alphago-zero-starting-from-scratch/)

[Mastering the game of Go without human knowledge](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)

# intro
[Residual neural network](https://en.wikipedia.org/wiki/Residual_neural_network)
- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

[Cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy)
- [The Key Equation Behind Probability](https://www.youtube.com/watch?v=KHVR587oW8I)

[Weight initialization](https://en.wikipedia.org/wiki/Weight_initialization)

[Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)
- [Backpropagation, intuitively | Deep Learning Chapter 3](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
- [The Most Important Algorithm in Machine Learning](https://www.youtube.com/watch?v=SmZmBKc7Lrs)

[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
- [Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://www.youtube.com/watch?v=IHZwWFHWa-w)

[Elo rating system](https://en.wikipedia.org/wiki/Elo_rating_system)

[Monte Carlo tree search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search)
- [Batch Monte Carlo Tree Search](https://arxiv.org/abs/2104.04278)

# network
residual network

policy and value in one network

# data pipeline

# perf
rust

numba

self play - 1 network forward pass + mcts
train - loss + backpropagation
eval - 2 networks forward pass + mcts
